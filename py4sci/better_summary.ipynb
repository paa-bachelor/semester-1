{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YXmFEtElTAxs",
        "QtUEtGqpTq0y",
        "A4JhEeNrXwEQ",
        "rt7jiwb_YW-n",
        "CaJJl0CqkuDy",
        "4empkbqIlBYl",
        "rPOSR6IglJoh",
        "PExHQmxJn4Cj",
        "cvkcj-9HUJKO",
        "TCznrlJyUFyx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Python for Scientists - 2023/2024\n",
        "\n",
        "Gunar Stevens"
      ],
      "metadata": {
        "id": "UWe6OSFHSjwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1 - Numerical limitations"
      ],
      "metadata": {
        "id": "YXmFEtElTAxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨ðŸ˜¨"
      ],
      "metadata": {
        "id": "G6G8S8aGTYlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2 - Numerical linear algebra"
      ],
      "metadata": {
        "id": "dN3UYA4wThfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Systems of linear equations"
      ],
      "metadata": {
        "id": "QtUEtGqpTq0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Notations and Terminology"
      ],
      "metadata": {
        "id": "NyDCPd_7TxSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A system of $m$ equations with $n$ variables can be written as:\n",
        "\\begin{cases}\n",
        "a_{11}x_1+a_{12}x_2+...+a_{1n}x_n = b_1\\\\\n",
        "a_{21}x_1+a_{22}x_2+...+a_{2n}x_n = b_2\\\\\n",
        "\\vdots\\\\\n",
        "a_{m1}x_1+a_{m2}x_2+...+a_{mn}x_n = b_n\\\\\n",
        "\\end{cases}\n",
        "\\\n",
        "Or in equivalent matrix form:\n",
        "$\\begin{bmatrix}\n",
        "a_{11}&a_{12}&...&a_{1n}\\\\\n",
        "a_{21}&a_{22}&...&a_{2n}\\\\\n",
        "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
        "a_{m1}&a_{m2}&...&a_{mn}\\\\\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "x_1\\\\x_2\\\\\\vdots\\\\x_n\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "b_1\\\\b_2\\\\\\vdots\\\\b_n\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "BOxhwDmmT8Iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A nxn matrix $\\textsf{A}$ is called **non-singular** if:\n",
        "- $\\textsf{A}$ has an inverse $\\textsf{A}^{-1}$ such that $\\textsf{A}^{-1}$$\\textsf{A} = \\textsf{I}_n$\n",
        "- det($\\textsf{A}$) = 0\n",
        "- rank($\\textsf{A}$) = n\n",
        "- For any vector $\\textsf{z} \\neq 0$, $\\textsf{Az}$ must also be nonzero.\n",
        "\n",
        "If $\\textsf{A}$ is non-singular, it always has a unique solution for any $\\textsf{b} \\in \\mathbb{R}^n$ in: $\\textsf{Ax = b}$"
      ],
      "metadata": {
        "id": "gpM1z9byWDgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2. LU factorization/ Gaussian elimination"
      ],
      "metadata": {
        "id": "A4JhEeNrXwEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual computation and Theoretical background"
      ],
      "metadata": {
        "id": "rt7jiwb_YW-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to transform our linear system into a **triangular linear system**, given a non-singular matrix $\\textsf{M}$ and the equation-to-solve $\\textsf{Ax = b}$, multiplying(left matrix multiplication) both sides by $\\textsf{M}$ yields the form $\\textsf{MAx = Mb}$, which has the same solution as the original system. We are to transform $\\textsf{A}$ into either a lower triangular matrix(a matrix where all the elements above the diagonal are zero), or upper triangular matrix(a matrix where all the elements below the diagonal are zero), and so we need to find the $\\textsf{M}$ that realises this.\n",
        "\n",
        "Generally speaking, for a $n$-vector **a**(the *$k$*th column in our matrix $\\textsf{A}$), we can annihilate all of its entries below the *$k$*th position (assuming $a_k \\neq 0$) by the following transformation:\n",
        "\n",
        "$\\textsf{M}_{ka}=\n",
        "\\begin{bmatrix}\n",
        "1&...&0&0&...&0\\\\\n",
        "\\vdots&\\ddots&\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
        "0&...&1&0&...&0\\\\\n",
        "0&...&-m_{k+1}&1&...&0\\\\\n",
        "\\vdots&\\ddots&\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
        "0&...&-m_n&0&...&1\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "a_1\\\\\\vdots\\\\a_k\\\\a_{k+1}\\\\\\vdots\\\\a_n\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "a_1\\\\\\vdots\\\\a_k\\\\0\\\\\\vdots\\\\0\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "with $m_i = \\frac{a_i}{a_k}$, $i = k+1,...,n$\n",
        "\n",
        "Here, $a_k$ is called the **pivot**, this very transformation is what one would call a **Gauss transformation**. After finding  $\\textsf{M}_{k}$ for every $k$ columns, the equations becomes:\n",
        "$\\textsf{M}_1\\textsf{M}_2...\\textsf{M}_k\\textsf{A}$**x** $= $$\\textsf{M}_1\\textsf{M}_2...\\textsf{M}_k$**b**, where $\\textsf{M}_1\\textsf{M}_2...\\textsf{M}_k\\textsf{A}$ is an upper triangular matrix $\\textsf{U}$, which makes the system easy to solve. $\\textsf{M}$ takes a similar form to 'craft' the lower triangular matrix $\\textsf{L}$, the difference is that the $m$-elements will be above the diagonal.\n",
        "\n",
        "One can write $\\textsf{Ax = b}$ as $\\textsf{LUx = b}$, where $\\textsf{A = LU}$."
      ],
      "metadata": {
        "id": "uBdYOXe8Ycb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python"
      ],
      "metadata": {
        "id": "N-LV3NECYZ_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "Fbjgg5_Ie_Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "from scipy.linalg import cho_solve, cholesky, inv, lu_factor, lu_solve, norm"
      ],
      "metadata": {
        "id": "FrrNQ1yMVRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given matrix $\\textsf{A}$ and vector **b**:"
      ],
      "metadata": {
        "id": "MQraH1ytfMHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 1/2, 1/3, 1/4, 1/5, 1/6],\n",
        "              [1/2, 1/3, 1/4, 1/5, 1/6, 1/7],\n",
        "              [1/3, 1/4, 1/5, 1/6, 1/7, 1/8],\n",
        "              [1/4, 1/5, 1/6, 1/7, 1/8, 1/9],\n",
        "              [1/5, 1/6, 1/7, 1/8, 1/9, 1/10],\n",
        "              [1/6, 1/7, 1/8, 1/9, 1/10, 1/11]])\n",
        "\n",
        "b = np.array([1, 2, 3, 4, 5, 6])"
      ],
      "metadata": {
        "id": "KLvSBFc2fIuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilise scipy's linalg.lu method on $\\textsf{A}$ to get the upper and lower triangular matrix, this is only necessary if one is interested in these matrices;"
      ],
      "metadata": {
        "id": "e9kS7wJLfl4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L, U = linalg.lu(A, permute_l=True)\n",
        "print(\"L:\")\n",
        "print(L)\n",
        "print(\"U:\")\n",
        "print(U)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEmunNirfkwu",
        "outputId": "c212d919-c753-405d-fc74-7e0bc166bfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L:\n",
            "[[ 1.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.5         1.         -0.93333333  1.          0.          0.        ]\n",
            " [ 0.33333333  1.          0.          0.          0.          0.        ]\n",
            " [ 0.25        0.9         0.56       -0.21428571  1.          0.        ]\n",
            " [ 0.2         0.8         0.85333333 -0.14285714  0.88888889  1.        ]\n",
            " [ 0.16666667  0.71428571  1.          0.          0.          0.        ]]\n",
            "U:\n",
            "[[ 1.00000000e+00  5.00000000e-01  3.33333333e-01  2.50000000e-01\n",
            "   2.00000000e-01  1.66666667e-01]\n",
            " [ 0.00000000e+00  8.33333333e-02  8.88888889e-02  8.33333333e-02\n",
            "   7.61904762e-02  6.94444444e-02]\n",
            " [ 0.00000000e+00  0.00000000e+00  5.95238095e-03  9.92063492e-03\n",
            "   1.22448980e-02  1.35281385e-02]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  9.25925926e-04\n",
            "   1.90476190e-03  2.70562771e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -2.04081633e-05 -5.15357658e-05]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00 -5.72619620e-07]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve the system $\\textsf{A}$**x**$=$**b**, we use scipy's linalg.solve;"
      ],
      "metadata": {
        "id": "I3m745sigGdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = linalg.solve(A, b)\n",
        "print(f'x = {x}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ooz3hegE62",
        "outputId": "01dae7cb-ba68-4d08-cafb-5a559ccd5554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = [   -216.00000004    7350.00000122  -57120.00000835  166320.00002181\n",
            " -201600.00002412   85932.00000952]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See also: partial pivoting"
      ],
      "metadata": {
        "id": "zf5qEHm-nPlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Cholesky Factorization"
      ],
      "metadata": {
        "id": "CaJJl0CqkuDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual computation and Theoretical background"
      ],
      "metadata": {
        "id": "4empkbqIlBYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a matrix $\\textsf{A}$ is symmetric($\\textsf{A}$ = $\\textsf{A}^T$) and positive definite(**x**$^{\\textsf{T}}\\textsf{A}$**x**$>0$ for all **x** $\\neq 0$) then we have $\\textsf{U} = \\textsf{L}^{\\textsf{T}}$ where $\\textsf{U}$ and $\\textsf{L}$ are the upper and lower triangular matrix respectively, meaning that $\\textsf{A} = \\textsf{LL}^{\\textsf{T}}$. Let's take a 2D example:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "a_{11}&a_{12}\\\\\n",
        "a_{21}&a_{22}\\\\\n",
        "\\end{bmatrix}=\n",
        "\\begin{bmatrix}\n",
        "l_{11}&0\\\\l_{21}&l_{22}\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "l_{11}&l_{21}\\\\0&l_{22}\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "l_{11}^2&l_{11}l_{21}\\\\\n",
        "l_{11}l_{21}&l_{21}^2+l_{22}^2\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Implying that:\n",
        "\\begin{cases}\n",
        "l_{11} = \\sqrt{a_{11}}\\\\\n",
        "l_{21} = a_{12}/l_{11}\\\\\n",
        "l_{22} = \\sqrt{a_{22} - l_{21}^2}\n",
        "\\end{cases}\n"
      ],
      "metadata": {
        "id": "l-bIQBoVlMgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python"
      ],
      "metadata": {
        "id": "rPOSR6IglJoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "nLR32nUwqDiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "from scipy.linalg import cho_solve, cholesky, inv, lu_factor, lu_solve, norm"
      ],
      "metadata": {
        "id": "aCNVksrglK2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a positive-definite, symmetric matrix $\\textsf{A}$ and vector **b**;"
      ],
      "metadata": {
        "id": "3mSkSvR5qIwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "    [4,2,6],\n",
        "    [2,2,5],\n",
        "    [6,5,22]\n",
        "])\n",
        "\n",
        "b = np.array([1, 2, 3])"
      ],
      "metadata": {
        "id": "1pTIUWOtqFMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate the lower and upper triangular matrix using scipy's linalg.cholesky method:"
      ],
      "metadata": {
        "id": "F_WaBlEAqXxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_ , U_ = linalg.cholesky(A, lower=True), linalg.cholesky(A, lower=False)\n",
        "#If lower = True, it will return the lower triangular matrix, if False, it will return the upper triangular matrix\n",
        "print(\"L_:\")\n",
        "print(L_)\n",
        "print(\"U_:\")\n",
        "print(U_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2suiUIPlqSi3",
        "outputId": "c1be9f45-8818-47c0-8177-44421e185566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L_:\n",
            "[[2. 0. 0.]\n",
            " [1. 1. 0.]\n",
            " [3. 2. 3.]]\n",
            "U_:\n",
            "[[2. 1. 3.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c,low = linalg.cho_factor(A,lower = True)\n",
        "print(f'c = {c}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfX30Shtr2RE",
        "outputId": "78e69411-4b48-4971-82fc-80384666a9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c = [[2. 2. 6.]\n",
            " [1. 1. 5.]\n",
            " [3. 2. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = linalg.cho_solve((c,low), b)\n",
        "print(f'x = {x}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZfOuJBjqg7l",
        "outputId": "006e8e62-9914-409f-8978-4b7f33d1ed95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = [-0.41666667  1.83333333 -0.16666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4. Sensitivity and conditioning"
      ],
      "metadata": {
        "id": "W0IOZrKLuVv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector norms"
      ],
      "metadata": {
        "id": "5aOdlXS5uhuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**p-norm**, general form of the norms defind below:\n",
        "\n",
        "$||$**x**$||$$_p$ $= (\\sum^n_{i=1}||x_i||^p)^{1/p}$\n",
        "\n",
        "**Manhattan norm** or 1-norm:\n",
        "\n",
        "$||$**x**$||$$_1$ = $\\sum^{n}_{i+1}||x_i||$\n",
        "\n",
        "**Euclidean norm** or 2-norm:\n",
        "\n",
        "$||$**x**$||$$_2$ = $\\sqrt{\\sum^n_{i=1}||x_i||^{2}}$\n",
        "\n",
        "**$\\infty$-norm** (thye limit for $p->âˆž$):\n",
        "\n",
        "$||$**x**$||$$_{\\infty}$ = max$||x_i||$ where $1\\le i \\le n$"
      ],
      "metadata": {
        "id": "lMRCy8sSuv7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example; consider the vector **x** = $[-4,3]^{\\textsf{T}}$\n",
        "\n",
        "$||$**x**$||$$_1$ = 7\n",
        "\n",
        "$||$**x**$||$$_2$ = 5\n",
        "\n",
        "$||$**x**$||$$_{\\infty}$ = 4\n",
        "\n",
        "In general we get; $||$**x**$||$$_{\\infty}$ $\\le$ $||$**x**$||$$_2$ $\\le$ $||$**x**$||$$_1$"
      ],
      "metadata": {
        "id": "Uq-xeTJuwcTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix norms"
      ],
      "metadata": {
        "id": "lcQ_zRLsxIXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The norm of a $m \\times n$ matrix $\\textsf{A}$ is given by:\n",
        "\n",
        "$||\\textsf{A}|| =$ max$\\frac{||\\textsf{Ax}||}{||\\textsf{x}||}$, where $\\textsf{x} \\neq 0$\n",
        "\n",
        "Which corresponds with 'the maximum stretching' the matrix induces in a vector."
      ],
      "metadata": {
        "id": "-wsP3Sh9Qr3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two cases that are easy to calculate:\n",
        "\n",
        "- $||\\textsf{A}||_1$, which corresponds to the maximum absolute *column* sum of the matrix: $||\\textsf{A}||_1 =$ max$_j \\sum^m_{i=1}||a_{ij}||$\n",
        "\n",
        "- $||\\textsf{A}||_{\\infty}$, which corresponds to the maximum absolute *row* sum of the matrix: $||\\textsf{A}||_{\\infty} =$ max$_{i} \\sum^n_{j=1}||a_{ij}||$"
      ],
      "metadata": {
        "id": "wxu-J1zSRXqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Condition Number"
      ],
      "metadata": {
        "id": "MvC-IgLaRNCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The condition number of a nonsingular square matrix $\\textsf{A}$ is defined as:\n",
        "\n",
        "cond($\\textsf{A}$) = $||\\textsf{A}||\\cdot||\\textsf{A}^{-1}||$\n",
        "\n",
        "By convention, the condition number of a singular matrix is $\\infty$. The condition number can be interpreted as a measure of how close a matrix is to being singular."
      ],
      "metadata": {
        "id": "DHYt3iZ3Zuk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Error Estimation"
      ],
      "metadata": {
        "id": "ujYfu0BCac-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a non-singular linear system $\\textsf{Ax = b}$ with solution $\\textsf{x}$. Also, let $\\textsf{x'}$ be the solutiojn to the perturbed system $\\textsf{Ax' = b} + \\Delta \\textsf{b}$, and define the difference between both solutions $\\textsf{x'-x} = \\Delta \\textsf{x}$. Utilising norm properties and the definitions stated above, one can find:\n",
        "\n",
        "$\\frac{||\\Delta \\textsf{x}||}{||\\textsf{x}||} \\le$ cond$(\\textsf{A})\\frac{||\\Delta \\textsf{b}||}{||\\textsf{b}||}$\n",
        "\n",
        "The condition number thus acts as an \"amplification factor\" for the relative change in the solution with respect to a relative change in the right hand sided vector.\n",
        "\n",
        "A similar inequality exists for deviations $\\textsf{E}$ in matrix $\\textsf{A}$, such that $(\\textsf{A+E})\\textsf{x'} = \\textsf{b}$, namely:\n",
        "\n",
        "$\\frac{||\\Delta \\textsf{x}||}{||\\textsf{x}||} \\le$ cond$(\\textsf{A})\\frac{||\\textsf{E}||}{||\\textsf{A}||}$"
      ],
      "metadata": {
        "id": "0VlDHP0vagJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example; suppose we have $\\textsf{Ax = b}$ given by:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "1&2&2\\\\4&4&2\\\\4&6&4\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "x_1\\\\x_2\\\\x_3\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "3\\\\6\\\\10\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Where the solution of the system is given by $\\textsf{x} = \\begin{bmatrix}\n",
        "-1&3&-1\\end{bmatrix}^{\\textsf{T}}$. If a perturbation/anomaly $\\Delta \\textsf{b} = \\begin{bmatrix}\n",
        "-1.8&0&0\\end{bmatrix}^{\\textsf{T}}$ is applied to the vector $\\textsf{b}$, the linear system to be solved becomes:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "1&2&2\\\\4&4&2\\\\4&6&4\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "x'_1\\\\x'_2\\\\x'_3\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "1.2\\\\6\\\\10\n",
        "\\end{bmatrix}$\n",
        "\n",
        "This system has a solution $\\textsf{x'} = \\begin{bmatrix}\n",
        "-2.8&6.6&-4.6\\end{bmatrix}^{\\textsf{T}}$, and so the difference between the two solutions is given by:\n",
        "\n",
        "$\\Delta \\textsf{x} = \\textsf{x'} - \\textsf{x} = \\begin{bmatrix}\n",
        "-1.8\\\\3.6\\\\-3.6\\end{bmatrix} \\implies \\frac{||\\Delta \\textsf{x}||_1}{||\\textsf{x}||_1} = 1.8$\n",
        "\n",
        "While:\n",
        "\n",
        "$\\frac{||\\Delta \\textsf{b}||_1}{||\\textsf{b}||_1} \\approx 0.095$\n",
        "\n",
        "With cond($\\textsf{A}$) $= 60$, the inequality found above becomes:\n",
        "\n",
        "$1.8 \\le 5.68$\n",
        "\n",
        "Which holds."
      ],
      "metadata": {
        "id": "JWiXtyISd1iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Residual"
      ],
      "metadata": {
        "id": "4K4CzokvhgTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **residual** $\\textsf{r}$ of an approximate solution $\\textsf{x'}$ of the system $\\textsf{Ax = b}$ is defined as:\n",
        "\n",
        "$\\textsf{r}$ = $\\textsf{b - Ax'}$\n",
        "\n",
        "If we multiply the system $\\textsf{Ax = b}$ by an arbitrary number, the solution will remain the same, whereas the residual will be multiplied by the same number. Therefore, it only makes sense to work with a relative residual:\n",
        "\n",
        "$\\frac{||\\textsf{r}||}{||\\textsf{A}||\\cdot ||\\textsf{x'}||}$\n",
        "\n",
        "One can relate the error to the residual via:\n",
        "\n",
        "$\\frac{||\\Delta \\textsf{x}||}{||\\textsf{x}||} \\le$ cond$(\\textsf{A})\\frac{||\\textsf{r}||}{||\\textsf{A}||\\cdot ||\\textsf{x'}||}$\n",
        "\n",
        "Therefore, a small residual implies a small relative error in the solution only if the matrix $\\textsf{A}$ has a small condition number."
      ],
      "metadata": {
        "id": "QQ9U9IJ2hoo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Linear Least Squares"
      ],
      "metadata": {
        "id": "PExHQmxJn4Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Theoretical Background"
      ],
      "metadata": {
        "id": "cvkcj-9HUJKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A method that solves/approximates $\\textsf{Ax = b}$ for **x**, where $\\textsf{A}$ is *overdetermined*. The method works by minimizing the square of the residual $\\textsf{r}$, hence it name. Suppose we're fitting a quadratic polynomial to 6 data points ($t_i,y_i$), then the *overdetermined* problem has the following general form:\n",
        "\n",
        "$\\textsf{Ax} =\n",
        "\\begin{bmatrix}\n",
        "1&t_1&t_1^2\\\\\n",
        "1&t_2&t_2^2\\\\\n",
        "1&t_3&t_3^2\\\\\n",
        "1&t_4&t_4^2\\\\\n",
        "1&t_5&t_5^2\\\\\n",
        "1&t_6&t_6^2\\\\\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "x_1\\\\x_2\\\\x_3\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "y_1\\\\y_2\\\\y_3\\\\y_4\\\\y_5\\\\y_6\n",
        "\\end{bmatrix} = \\textsf{b}\n",
        "$\n",
        "\n",
        "Note that a matrix, such as $\\textsf{A}$, where the columns are successive powers of some independent variable is called a *Vandermonde matrix*. Transforming our $t$-data into such a matrix makes sense once you start doing matrix vector multiplication."
      ],
      "metadata": {
        "id": "xL4rGgAVRtlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "qed"
      ],
      "metadata": {
        "id": "3I-mQ2dkYcLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python"
      ],
      "metadata": {
        "id": "TCznrlJyUFyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "lV8MzMG9UW21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import lstsq"
      ],
      "metadata": {
        "id": "GWQ8rn70UE5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we have 11 data points, a $y$-value for every independent $x$-value."
      ],
      "metadata": {
        "id": "Bf6v9emuUeJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y = np.array([2.9, 4.8, 7.1, 7.7, 9.4, 9.6, 10.2, 8.3, 9.0, 6.6, 4.1])"
      ],
      "metadata": {
        "id": "amNbMzMlVCvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to fit a quadratic polynomial to our data, hence we must transform our $x$-data into a *Vandermonde matrix*."
      ],
      "metadata": {
        "id": "phcOghA0VIjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = x[:, np.newaxis]**[0,1,2]\n",
        "print(M)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8E7vbYaVH1T",
        "outputId": "f7759f28-de9b-4229-933e-df3989c22b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  1   0   0]\n",
            " [  1   1   1]\n",
            " [  1   2   4]\n",
            " [  1   3   9]\n",
            " [  1   4  16]\n",
            " [  1   5  25]\n",
            " [  1   6  36]\n",
            " [  1   7  49]\n",
            " [  1   8  64]\n",
            " [  1   9  81]\n",
            " [  1  10 100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to find the least-squares solution to M.dot(p) = y,\n",
        "# where p is a vector with length 3 that holds the parameters a and b an c.\n",
        "p, res, rnk, s = lstsq(M, y)\n",
        "\n",
        "print(p)"
      ],
      "metadata": {
        "id": "VgFh-Uk6n6Jx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c728cc-dfdb-4870-e0bc-2941710eb389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.6048951   2.65037296 -0.2460373 ]\n"
          ]
        }
      ]
    }
  ]
}